{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Remove warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Basic libraries\n",
    "#\n",
    "import random\n",
    "import time\n",
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "from   tqdm      import tqdm\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Visualization library\n",
    "#\n",
    "import matplotlib.pyplot   as plt \n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Sklearn library\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#\n",
    "# TabNet library\n",
    "#\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#\n",
    "# User libraries\n",
    "#\n",
    "from utils.PerformanceMetrics import RegressionEvaluation\n",
    "from utils.plot_scatter       import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#\n",
    "filename   = 'metadata/7-kanal-1.csv'\n",
    "\n",
    "Transformation  = True\n",
    "Scaling         = 'Standard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lag        =   12\n",
    "Horizon    =   6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "# Load data\n",
    "#\n",
    "df = pd.read_csv( filename )\n",
    "\n",
    "print('[INFO] Data imported')\n",
    "print('[INFO] Time: %.2f seconds' % (time.time() - start))\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to 'datetime64'\n",
    "#\n",
    "df['Date'] = df['Date'].astype('datetime64')\n",
    "\n",
    "# Set index\n",
    "#\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "df = df.resample('5min').mean().interpolate()\n",
    "df = pd.DataFrame( df['PM2.5'] )\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetSeries = df.columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int( df.shape[0] * 0.8 )\n",
    "\n",
    "df_train = df[ :idx ]\n",
    "df_test  = df[ idx: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(20, 3) )\n",
    "\n",
    "df_train.plot(ax=ax, color='tab:blue' )\n",
    "df_test.plot(ax=ax,  color='tab:orange')\n",
    "\n",
    "plt.legend(['Training', 'Testing'], frameon = False, fontsize = 14)\n",
    "plt.ylabel(targetSeries, size = 14)\n",
    "plt.xlabel('Date', size = 14);\n",
    "plt.xticks(size = 12);\n",
    "plt.yticks(size = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_train.iloc[-Lag:], df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Transformation == True):\n",
    "    \n",
    "    print('[INFO] Data transformation applied')\n",
    "    \n",
    "    VALUE = max(df.min().min(), 1.0)\n",
    "    \n",
    "    df_train = np.log( df_train + VALUE)\n",
    "    df_test  = np.log( df_test  + VALUE)\n",
    "    \n",
    "else:\n",
    "    print('[INFO] No data transformation applied.')  \n",
    "    \n",
    "VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Scaling == 'MinMax'):\n",
    "    print('[INFO] Scaling: MinMax')\n",
    "    \n",
    "    # Set scaler\n",
    "    #\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    df_train[targetSeries] = scaler.fit_transform( df_train[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "    df_test[targetSeries]  = scaler.transform( df_test[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "        \n",
    "elif (Scaling == 'Robust'):\n",
    "    print('[INFO] Scaling: Robust')\n",
    "    \n",
    "    # Set scaler\n",
    "    #\n",
    "    scaler = RobustScaler()\n",
    "     \n",
    "    df_train[targetSeries] = scaler.fit_transform( df_train[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "    df_test[targetSeries]  = scaler.transform( df_test[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "        \n",
    "elif (Scaling == 'Standard'):\n",
    "    print('[INFO] Scaling: Standard')\n",
    "    \n",
    "    # Set scaler\n",
    "    #\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    df_train[targetSeries] = scaler.fit_transform( df_train[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "    df_test[targetSeries]  = scaler.transform( df_test[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "           \n",
    "else:\n",
    "    print('[WARNING] Unknown data scaling. Standar scaling was selected')   \n",
    "    \n",
    "    # Set scaler\n",
    "    #\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    df_train[targetSeries] = scaler.fit_transform( df_train[ targetSeries ].to_numpy().reshape(-1,1) )\n",
    "    df_test[targetSeries]  = scaler.transform( df_test[ targetSeries ].to_numpy().reshape(-1,1) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training/Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, look_back=1, Horizon = 1, SeriesName ='', overlap = 1):\n",
    "    \n",
    "    # Check if SeriesName exists in dataset\n",
    "    #\n",
    "    if (SeriesName not in df.columns):\n",
    "        SeriesName = df.columns[-1]\n",
    "    \n",
    "    \n",
    "    date, dataX, dataY = [], [], []\n",
    "\n",
    "    for i in tqdm( range(0, df.shape[0] + 1  - look_back - Horizon, overlap) ):\n",
    "                    \n",
    "        \n",
    "        data = df[i:(i+look_back+Horizon)].copy()\n",
    "        # Not sequental interval\n",
    "        #\n",
    "        if (data.reset_index().diff()[1:].nunique()['Date'] > 1): continue\n",
    "         \n",
    "        # X\n",
    "        #\n",
    "        # Lag-Instances from Target Series\n",
    "#         A = data[ SeriesName ].to_numpy()[:look_back].flatten()        \n",
    "#         # Information from other features (only from current time)\n",
    "#         B = data.iloc[look_back-1, data.columns != SeriesName].to_numpy()\n",
    "#         # Concatenate all information - Instance created\n",
    "#         dataX.append( np.concatenate([A, B]) )\n",
    "        \n",
    "#         dataX.append( data[ SeriesName ].to_numpy()[:look_back].flatten() )\n",
    "\n",
    "\n",
    "\n",
    "        A = data[ SeriesName ].to_numpy()[:look_back].flatten()        \n",
    "        # Information from Moving-Average features\n",
    "        B = np.array([\n",
    "                       data[:look_back][ SeriesName ].to_numpy()[-4:].mean(),\n",
    "                       data[:look_back][ SeriesName ].to_numpy()[-7:].mean(),\n",
    "                       data[:look_back][ SeriesName ].to_numpy().mean(),     \n",
    "                       #\n",
    "                       data[:look_back][ SeriesName ].to_numpy()[-4:].std(),\n",
    "                       data[:look_back][ SeriesName ].to_numpy()[-7:].std(),    \n",
    "                       #\n",
    "                       np.sin( data.index.hour[look_back] + data.index.minute[look_back] / 60.0 ),\n",
    "                       np.cos( data.index.hour[look_back] + data.index.minute[look_back] / 60.0 )\n",
    "                      ])\n",
    "        # Concatenate all information - Instance created\n",
    "        dataX.append( np.concatenate([A, B]) )\n",
    "\n",
    "\n",
    "\n",
    "        # ALL DATA: dataX.append( data.to_numpy()[:look_back].flatten() )\n",
    "\n",
    "\n",
    "        # Y\n",
    "        #\n",
    "        dataY.append( data[ SeriesName ].to_numpy()[ look_back : look_back + Horizon] )\n",
    "        \n",
    "        # Date (ahead) - Needed for visualization\n",
    "        #\n",
    "        date.append( data.index[ look_back : look_back + Horizon] )\n",
    "                      \n",
    "    return ( np.array(dataX), np.array(dataY), np.array(date) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, _ = create_dataset(df           = df_train, \n",
    "                                   look_back    = Lag, \n",
    "                                   Horizon      = Horizon, \n",
    "                                   SeriesName   = targetSeries,\n",
    "                                   overlap      = 1,\n",
    "                                   )\n",
    "\n",
    "testX,  testY, _  = create_dataset(df           = df_test, \n",
    "                                   look_back    = Lag, \n",
    "                                   Horizon      = Horizon, \n",
    "                                   SeriesName   = targetSeries,\n",
    "                                   overlap      = Horizon,)\n",
    "\n",
    "\n",
    "\n",
    "print('Training instances:   %6i' % trainX.shape[0])\n",
    "print('Testing instances:    %6i' % testX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting model: TabNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabNetRegressor(verbose = 1, \n",
    "                        seed    = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "# Train model\n",
    "#\n",
    "model.fit(X_train = trainX, \n",
    "          y_train = trainY,\n",
    "          loss_fn = nn.MSELoss(), # nn.L1Loss(), nn.MSELoss()\n",
    "          #\n",
    "          eval_set    = [(testX, testY)],\n",
    "          batch_size  = 32,\n",
    "          num_workers = 0,\n",
    "          patience    = 300, \n",
    "          max_epochs  = 2000,\n",
    "          eval_metric = ['rmse'])\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "stop = time.time()\n",
    "\n",
    "print('[INFO] Time %.2f' % (stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "#\n",
    "pred = model.predict( testX )\n",
    "\n",
    "\n",
    "# # Get prediction of each component tree\n",
    "# #\n",
    "# predictions = []\n",
    "# for Tree in model.estimators_:\n",
    "#     predictions += [ Tree.predict( testX ) ]\n",
    "    \n",
    "# predictions = np.array( predictions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply inverse scaling/transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply inverse scaling\n",
    "#\n",
    "for i in range( Horizon ):\n",
    "    testY[:,  i] = scaler.inverse_transform( testY[:,  i].reshape(-1,1) ).squeeze(-1)\n",
    "    pred[:, i]   = scaler.inverse_transform( pred[:, i].reshape(-1,1) ).squeeze(-1)\n",
    "\n",
    "\n",
    "# Apply inverse transformation   \n",
    "#\n",
    "if (Transformation == True):\n",
    "    testY = np.exp( testY ) - VALUE\n",
    "    pred = np.exp( pred )   - VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Feature: ', targetSeries)\n",
    "print('------------------------------------------------')\n",
    "Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "for i in range( Horizon ):\n",
    "\n",
    "    Prices = pd.DataFrame([])        \n",
    "\n",
    "    Prices[targetSeries] = testY[:,i]\n",
    "    Prices['Prediction'] = pred[:,i]\n",
    "\n",
    "\n",
    "    # Evaluation\n",
    "    #\n",
    "    MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "\n",
    "    # Store results\n",
    "    #\n",
    "    Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "    Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "    Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "    Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "\n",
    "#     # Present results\n",
    "#     #\n",
    "#     print('Horizon: ', i)\n",
    "#     print('> MAE:   ', MAE)\n",
    "#     print('> RMSE:  ', RMSE)\n",
    "#     print('> SMAPE: ', SMAPE)\n",
    "#     print('> R2:    ', R2)\n",
    "#     print()\n",
    "    \n",
    "    print('Horizon: %2i MAE %5.2f SMAPE: %5.2f R2: %.2f' %(i+1, MAE, SMAPE, R2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Feature: ', targetSeries)\n",
    "print('------------------------------------------------')\n",
    "Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "for i in range( Horizon ):\n",
    "\n",
    "    Prices = pd.DataFrame([])        \n",
    "\n",
    "    Prices[targetSeries] = testY[:,i]\n",
    "    Prices['Prediction'] = pred[:,i]\n",
    "            \n",
    "            \n",
    "    # Plot Real & Predicted values\n",
    "    #\n",
    "    Prices[:100].plot( figsize = (20, 3), marker = 'o' )\n",
    "    #\n",
    "    plt.title('Feature: {} - Horizon = {}'.format(targetSeries, i+1))\n",
    "    plt.legend( frameon = False, fontsize = 14)\n",
    "    plt.xticks(size = 12)\n",
    "    plt.yticks(size = 12)\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots = [331, 332, 333, 334, 335, 336,  337, 338, 339]\n",
    "plt.figure( figsize = (20, 8) )\n",
    "RandomInstances = [113, 34, 141, 325, 139, 185, 188, 27, 31]\n",
    "\n",
    "\n",
    "for plot_id, i in enumerate(RandomInstances):\n",
    "\n",
    "    plt.subplot(subplots[plot_id])\n",
    "    #\n",
    "    plt.plot(range(Lag, Lag + Horizon), testY[i], color='g', marker = 'o', linewidth = 2)\n",
    "    plt.plot(range(Lag, Lag + Horizon), pred[i],  color='r', marker = 'o', linewidth = 2)\n",
    "\n",
    "    plt.legend(['Instance', 'Future values', 'Prediction'], frameon = False, fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots = [331, 332, 333, 334, 335, 336,  337, 338, 339]\n",
    "plt.figure( figsize = (20, 8) )\n",
    "RandomInstances = [random.randint(1, testY.shape[0]) for i in range(0, 9)]\n",
    "\n",
    "for plot_id, i in enumerate(RandomInstances):\n",
    "\n",
    "    plt.subplot(subplots[plot_id])\n",
    "    plt.grid()\n",
    "#     plot_scatter(range(0, Lag),             testX[i,:Lag], color='b')\n",
    "    plt.plot(range(Lag, Lag + Horizon), testY[i], color='g', marker = 'o', linewidth = 2)\n",
    "    plt.plot(range(Lag, Lag + Horizon), pred[i],  color='r', marker = 'o', linewidth = 2)\n",
    "\n",
    "    plt.legend(['Instance', 'Future values', 'Prediction'], frameon = False, fontsize = 12)\n",
    "#     plt.ylim([0, 8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outputs = pd.DataFrame([])\n",
    "#\n",
    "#\n",
    "Outputs[targetSeries] = testY.flatten()\n",
    "Outputs['TabNet']         = pred.flatten()\n",
    "#\n",
    "Outputs.to_csv('Predictions/TabNet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.1979064941406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
